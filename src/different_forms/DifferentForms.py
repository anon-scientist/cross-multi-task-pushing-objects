"""
$-task pushing objects scenario
TODO: take condifuration of tracks and tasks from bash file. Or at least tasks, and call skript.py in this bash to generate tracks
"""
import matplotlib
import os
from gazebo_sim.simulation import GenericEnvironment
from gazebo_sim.simulation import ThreePiTask, ThreePiEnvironment ;
from gazebo_sim.simulation import TwistAction, ThreePiManager ;
from scipy.spatial.transform import Rotation
import numpy as np ;
import time ;
import math ;
import argparse ;
from cl_experiment.parsing import Kwarg_Parser ;
import gymnasium as gym ;


def define_robot_actions():
    ## Action space of the Robot. Move actions 1-3 are such that the distance of .45m to target can be easily traversed in a single episode
    raw_action_space = np.array([[0.,0.],[0.5,0.3],[0.3,0.5],[0.4,0.4]]) ; # stop, turn right, turn left, straight
    actions = []
    for e in raw_action_space:
      label = "" ;
      if e[0]+e[1] < 0.0001: label = "stop" ;
      elif e[0] == e[1]: label = "straight" ;
      elif e[0] >= e[1]: label = "right" ;
      elif e[0] <= e[1]: label = "left" ;
      actions.append(TwistAction(label, e))
    print("Nr actions is ", len(actions)) ;
    return actions ;

def transform_full_to_simplified_action(simplified_action):
    return 0 if simplified_action == 0 else 1 ;


def transform_simplified_to_full_action(simplified_action, steering_guide):
      # Now we have an action that can either be 0 or 1. Non-adaptive control now transforms this into a full action
      if simplified_action == 0: # stop --> perform stop action
        return 0 ;
      elif simplified_action==1: # continue --> use non-adaptive controller to determine direction
        # decision is based on argmax of viewing angle popcode, 0 (included) to 9 (included)
        if steering_guide  < 7:
          return 1 ; # left
        elif steering_guide > 7:
          return 2 ; # right
        else:
          return 3 ; # straight


class DifferentFormsWrapper(ThreePiEnvironment):

    def __init__(self, step_duration_nsec=100 * 1000 * 1000,  **kwargs) -> None:
    
        args = self.parse_args(**kwargs) ;
        root_dir = args.root_dir ;
        self.fake_inputs = args.fake_inputs ;
        self.external_steering = args.external_steering ;
        ## Possible tracks, with a single cube each. Will be read from obj_data.txt generated by simulation/gazebo_sim/skript.py 
        ## This never changes 
        single_tasks = {}
        directory_path = os.path.join(root_dir, 'simulation', 'gazebo', 'skript_world', 'world', 'obj_data.txt')   ;
        with open(directory_path, 'r') as file:
            i = 0;
            for line in file:
                parts = line.strip().split()
                name = parts[0]
                x = float(parts[1])
                y = float(parts[2])
                mass = float(parts[3])
                single_tasks[name] = {"name": name, "pos": [-0.5,y,0.0], "mass": mass } ;
                i+=1

        ## define agregate tasks based on another file
        tasks = [] ;
        #file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', '..','tasks.txt') ;
        file_path = os.path.join(root_dir, 'tasks.txt')   ;
        if os.path.exists(file_path):
          task_definitions = [l.strip() for l in open(file_path,"r").readlines()] ;
          for i,line in enumerate(task_definitions):
            if len(line) <= 1: continue ;
            task = ThreePiTask(name="task"+str(i)) ;
            #print("spawned task" + str(i)) ;
            for subtask_name in line.split():
              #print("adding subtask", subtask_name) ;
              tpl = single_tasks[subtask_name] ;
              trafo1 = ThreePiTask.Transform(position = tpl["pos"], euler_rotation = [0.0,0.0,15]) ;
              trafo2 = ThreePiTask.Transform(position = tpl["pos"], euler_rotation = [0.0,0.0,-15]) ;
              task.add_starting_point({"name": subtask_name + "_1", "trafo": trafo1, "mass":tpl["mass"]}) ; 
              task.add_starting_point({"name": subtask_name + "_2", "trafo": trafo2, "mass":tpl["mass"]}) ; 
            tasks.append(task) ;
            #print ("Task is", task.starting_points) ;
        else:
          print("Task definition file tasks.txt not found!") ;
          sys.exit(0) ;

        actions = define_robot_actions() ;

        # Configure obs space and manager
        obs_shape = [20,20,3] if self.fake_inputs == "no" else [3,15,1] ;
        env_config = {"observation_shape":obs_shape,"tasks":tasks,"actions":actions,"robot_name":'3pi_robot_with_front_cam',"vehicle_prefix":'/vehicle',
                                       "lidar":'/vehicle/lidar',"world_name":'/world/Forschungsprojekt_world',"camera_topic":'/vehicle/camera', 
                                       "contact_topic":"/vehicle/contact_sensor" }

        # calling the superclass constructor will instantiate the manager
        super().__init__(env_config,step_duration_nsec, **kwargs)

        self.info = {
           'input_dims': self.observation_shape,
           'number_actions': self.nr_actions,
        }

    @property
    def action_space(self):
      return gym.spaces.Discrete(2) if self.external_steering == "yes" else gym.spaces.Discrete(4) ;

    @property
    def observation_space(self):
      return gym.spaces.Box(0,1,shape=(3,15,1), dtype=np.float32) if self.external_steering == "yes" else gym.spaces.Box(0,1,shape=(20,20,3),dtype=np.float32) ;


    def get_current_status(self):
        #print("get_curr_status")
        obj_name = self.info['object'][0]
        return (self.info['object'][1], self.current_mass)

    def switch(self, task_index: int) -> None:
        super().switch(task_index)
        #print(len(self.tasks))
        self.task_id = self.tasks[task_index].name ;
        print("switching to task", self.task_id, task_index)
        #time.sleep(30)

        self.current_task = self.tasks[task_index] ;
        self.current_name  = "" ;
        self.current_mass = -1 ;
        self.info['object'] = (None, None) ;


    def package_observation(self,vis,laser,pose):
        if self.fake_inputs == "yes":
          vis = self.create_fake_vis_signal() ;
          self.steering_guide = vis[2,:].argmax() ;
        else:
          self.steering_guide = -1 ;

        return {"vis" : vis, "laser" : laser, "pose" : pose } ;

    def reset(self, **kwargs):
        self.step_count = 0 ;
        random_starting_point= self.current_task.get_random_start()
        start_transform = random_starting_point["trafo"] ;
        self.current_name = random_starting_point["name"] ;
        self.current_mass = random_starting_point["mass"] ;
        self.info["object"] = (self.current_name, self.current_mass) ;
        print("Reset to OR:", start_transform.orientation)

        self.manager.trigger_pause(False) ;

        # to be on the safe side: wait until dynamic_pose_info messages prove that the robot is in the scene
        # important for 1st episode ever
        while self.manager.get_robot_name_in_sim() is None:
          print("Waiting before removal for robot to appear") ;
          time.sleep(0.25) ;

        # now that we know it exists, the robot may be removed
        self.manager.remove_robot() ;

        # now we wait until the robot is removed, signaled by dynamic_pose_info callbacks
        while self.manager.get_robot_name_in_sim() is not None:
          print("Waiting for robot removal") ;
          time.sleep(0.25)  ;
        self.manager.spawn_robot(start_transform.position,start_transform.orientation) ;

        # now we wait until the robot appears again, signaled by dynamic_pose_info callbacks
        while self.manager.get_robot_name_in_sim() is None:
          print("Waiting for robot to appear") ;
          time.sleep(0.25)  ;
        self.manager.gz_perform_action_stop()
        self.manager.reset_contact_state() ;

        # wait until robot has fallen to ground
        time.sleep(0.25) ;
 
        # get first observation in episode
        vis, laser, pose, contacts = self.get_observation(nsec=self.step_duration_nsec)

        self.manager.trigger_pause(True)

        #state = np.zeros([80,80,3])  ;
        vis = self.manager.convert_image_msg(vis) ;
        vis = vis[::4,::4,:]

        _, _, _ = self._compute_reward(vis,laser,pose,contacts,-1) ;
        self.last_obs = self.package_observation(vis, laser, pose) ;

        return self.last_obs, self.info ;


    def step(self, action_index: int):
        processed_action_index = action_index ;
        if self.config.external_steering == "yes": # in this case, fake_inbuts must be true as well, ensured by constructor
          processed_action_index = transform_simplified_to_full_action(action_index, self.steering_guide) ; # self.steering_guide was updated in last call 2 step or reset
          print("SG2!!!!!", action_index, processed_action_index) ;

        self.perform_action(action_index=processed_action_index) ;

        self.manager.trigger_pause(False) ;

        self.step_count += 1 ;

        vis, laser, pose, contacts = self.get_observation(nsec=self.step_duration_nsec) ;

        self.manager.trigger_pause(True) ;

        # make a decent np array out of the received observation
        #state = np.zeros([80,80,3]) # if we subscribe to /clock
        vis = self.manager.convert_image_msg(vis) ;
        # downsample for speed
        vis=vis[::4,::4,:] ;

        reward, terminated, truncated = self._compute_reward(vis,laser,pose, contacts, action_index) ;
        print(f'Step: {self.step_count:<4}, Action: {self.action_entries[processed_action_index].name:<8}, Cube: {self.current_name:<8}, Mass: {self.current_mass:<3}, Reward: {reward}, Range: ...')
        self.last_obs =  self.package_observation(vis, laser, pose) ;
        #print(obs)
        #np.savez("obs.npz", obs) ;
        return self.last_obs,reward,terminated,truncated, self.info ;


    # create visual signal containing popcodes for color, form, symbol, distance and viewing angle
    def create_fake_vis_signal(self):
        print(self.current_name, self.view_angle, self.smallest_valid_dist) ; # 
        forms = {"Cube":0, "Pyramide":1, "Sphere":2, "Cylinder":3, "D8":4 } ;
        symbols = {"X":0, "H":1, "Hash":2, "O":3, "A":4, "plain":5} ;
        colors ={"blue":0, "white":1, "red":2, "pink":3, "green":4} ;
        form, symbol, color, _ = self.current_name.split("_") ;
        form_index = forms[form] ;
        color_index = colors[color] ;
        symbol_index = symbols[symbol] ;
        # convert dist_index to 0..10 range  by normalizing it by the maximum range of 0.5m
        dist_index = int(self.smallest_valid_dist / 0.51 * 15) ;
        dist_index = dist_index if dist_index  <= 14 else 14
        # normalize view_angle reading to 0..10 range by clipping it and normalizing it to -25..25
        clipped_view_angle = -25 if self.view_angle < -25 else self.view_angle ;
        clipped_view_angle = 25 if clipped_view_angle > 25 else clipped_view_angle ;
        angle_index = int((clipped_view_angle - (-25) + 0.5 * 51./15) / 51. * 15) ;
        angle_index = 14 if angle_index >= 14 else angle_index ;
        print("!!!!!fake_vis!!! angle", self.view_angle, "index", angle_index, "dist", dist_index) ;

        final_pc = np.zeros([3,15, 1],dtype=np.float32) ;
        # row 0: encodes form and color
        final_pc[0,form_index] = 1 ;
        final_pc[0,5+color_index] = 1 ;
        final_pc[0,10+color_index] = 1 ;
        # row 2: encodes dist
        final_pc[1,dist_index] = 1 ;
        # row 3: encodes angle
        final_pc[2,angle_index] = 1 ;
        return final_pc ;
 


    # very clumsy way of adding new parameters to those read by superclass, but hey...
    def parse_args(self, **kwargs):
        parser = Kwarg_Parser(**kwargs) ;
        parser.add_argument("--fake_inputs", type=str, default="no",required=False ) ;
        parser.add_argument("--external_steering", type = str, required = False, default = "no") ;

        cfg,unparsed = parser.parse_known_args() ;

        if cfg.external_steering == "yes" and cfg.fake_inputs == "no":
          print("External steering xannot be used with real inputs!!") ;
          sys.exit(0) ;

  
        # parse superclass params
        old_cfg = GenericEnvironment.parse_args(self, **kwargs) ;
        
        for attr in dir(old_cfg):
          # exclude magic methods and private fields
          if len(attr) > 2 and (attr[0] != "_" and attr[1] != "_"):
            setattr(cfg, attr,getattr(old_cfg, attr)) ;
        return cfg ;

    def _compute_reward(self, vis, laser, position, contacts, action_index):
    
        truncated = False
        terminated = False

        state = vis ;

        # this is a wide view from -2 rad to 2 rad, far more than 180 deg
        full_ranges = np.array(laser) ;
        nr_beams = full_ranges.shape[0]
        #print(full_ranges[nr_beams//2-15:nr_beams//2+15]) ;

        angle_range_rad = 2.0 ;
        center_angle = 25. # +- 25 deg
        beams_per_deg = (nr_beams//2) / (angle_range_rad / (3.14) * 180.)   ;

        # store this for fake vision signal computration later in step()
        full_mask = np.logical_and((full_ranges != np.inf), (full_ranges < 1.0)).astype(np.float32) ;
        smallest_valid_dists = np.array([x for x,mask_entry in zip(full_ranges, full_mask) if mask_entry > 0.1 ]) ;
        self.smallest_valid_dist = smallest_valid_dists.min() if len(smallest_valid_dists) > 0 else 1. ;
 

        # compute center of gravity from all beams
        # >0 reward is only given if cog is in the central range
        modifier = 0.1 if action_index == 0 else 1.0 ; # punish stop action
        tmp = np.arange(0,nr_beams) - nr_beams // 2 ; 
        full_mask_sum = full_mask.sum() ;
        # computer center of gravity for on-object beams
        cog_in_beams = (tmp * full_mask).sum() / (full_mask_sum if full_mask_sum > 0. else 1.) ;
        cog_in_deg = cog_in_beams / beams_per_deg ;
        # store this for fake vision signal computration later in step()
        self.view_angle = cog_in_deg ;
        raw_reward = 1.0 - math.fabs(cog_in_deg)/ center_angle ;
        reward = 0.0 if raw_reward < 0.0 else raw_reward ;

        if full_mask_sum <= 0. or raw_reward < 0.:
            truncated  = True ;
            terminated = False ;
            print("COND: LOST", cog_in_deg)
            return -1., truncated, terminated ;
        
        if contacts is not None:
          #print("CCCCC", contacts) ;
          if len(contacts) >= 1: # frontally touched cube
            truncated = True
            terminated = False ;
            if self.current_mass > 1: # we mean > 0 but safer this way
                reward = -10
            else:
                reward = 10
            print("COND: Pushed object")
            return reward, truncated, terminated ;        


        if self.step_count >= self.max_steps_per_episode:
            terminated = True
            print("COND: MAX STEPS REACHED")
            return reward*modifier, truncated, terminated ;
        else:
            print("COND: Normal", reward, cog_in_deg, self.smallest_valid_dist) ;
            return reward * modifier, truncated, terminated ;


# Differentforms env but dict observations replaced by their "vis" entry
class DifferentFormsWrapperVis(DifferentFormsWrapper):
  def filter(self, d):
    return d["vis"] ;

  def reset(self, **kwargs):
    obs, info = DifferentFormsWrapper.reset(self, **kwargs) ;
    return self.filter(obs), {} ;

  def step(self, action):
    obs, reward, term, trunc, info = DifferentFormsWrapper.step(self, action) ;
    return self.filter(obs), reward, term, trunc, info ;

